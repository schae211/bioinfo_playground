<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Philipp SL Schäfer" />


<title>Integration via CCA</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bioinfo Playground</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Content
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="iterative_lsi.html">Iterative LSI</a>
    </li>
    <li>
      <a href="integration_cca_2.html">Integration via CCA</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Integration via CCA</h1>
<h4 class="author">Philipp SL Schäfer</h4>
<h4 class="date">2022-04-11-14-18</h4>

</div>


<pre class="r"><code>suppressPackageStartupMessages({
   library(tidyverse)
   library(ComplexHeatmap)
   library(grid)
   library(gridExtra)
   library(CCA)
   library(GGally)
})
Sys.setenv(RETICULATE_PYTHON =
             &quot;/home/pschaefer/miniconda3/envs/r-reticulate/bin/python&quot;)</code></pre>
<div id="status" class="section level1">
<h1>Status</h1>
<p>Work in progress.</p>
</div>
<div id="overview" class="section level1">
<h1>Overview</h1>
<ol style="list-style-type: decimal">
<li><p>CCA Objective</p></li>
<li><p>Classic Example</p></li>
<li><p>Solution via SVD</p></li>
<li><p>Implementation</p></li>
<li><p>Application to single cell data</p></li>
</ol>
<p>5a) Integration of two scRNA-seq datasets</p>
<p>5b) Integration of scRNA-seq and scATAC-seq datasets</p>
<ul>
<li>In particular we want to transfer RNA-seq counts and the celltype labels from the scRNA-seq dataset to the scATAC-seq datasets</li>
</ul>
</div>
<div id="resources" class="section level1">
<h1>Resources</h1>
<ul>
<li><p>Lecture: Data Mining, Spring 2013, by Ryan Tibshirani, lectures 10 - 13 (see here: <a href="https://www.stat.cmu.edu/~ryantibs/datamining/" class="uri">https://www.stat.cmu.edu/~ryantibs/datamining/</a>)</p></li>
<li><p>PhD Thesis: Practical Algorithms for Latent Variable Models by Gregory W. Gundersen (<a href="http://gregorygundersen.com/publications/gundersen2021thesis.pdf" class="uri">http://gregorygundersen.com/publications/gundersen2021thesis.pdf</a>)</p></li>
<li><p>Applied CCA in R: <a href="https://stats.oarc.ucla.edu/r/dae/canonical-correlation-analysis/" class="uri">https://stats.oarc.ucla.edu/r/dae/canonical-correlation-analysis/</a></p></li>
<li><p>Paper: A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis <span class="citation">(<a href="#ref-10.1093/biostatistics/kxp008" role="doc-biblioref"><em>1</em></a>)</span></p></li>
<li><p>Paper: Comprehensive Integration of Single-Cell Data (Seurat V3) <span class="citation">(<a href="#ref-10.1038/nbt.4096" role="doc-biblioref"><em>2</em></a>, <a href="#ref-10.1016/j.cell.2019.05.031" role="doc-biblioref"><em>3</em></a>)</span></p></li>
</ul>
</div>
<div id="cca-objective" class="section level1">
<h1>CCA Objective</h1>
<p>Given two datasets <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>,</p>
<ul>
<li><p><span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span> with observation <span class="math inline">\(g = 1,...N\)</span> and features <span class="math inline">\(Q^A_c\)</span> with <span class="math inline">\(c=1,...,M\)</span></p></li>
<li><p><span class="math inline">\(Y \in \mathbb{R}^{N \times P}\)</span> with observation <span class="math inline">\(g = 1,...N\)</span> and features <span class="math inline">\(Q^B_d\)</span> with <span class="math inline">\(d=1,...,P\)</span></p></li>
</ul>
<p>Our goal is to find linear combinations of the columns of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, such that the resulting vectors of length <span class="math inline">\(N\)</span> are maximally correlated.</p>
<p>In mathematical terms we seek to find the canonical correlation vectors <span class="math inline">\(\hat{h_X}\)</span> and <span class="math inline">\(\hat{h_Y}\)</span> such that <span class="math inline">\(X \hat{h_X}\)</span> and <span class="math inline">\(Y \hat{h_Y}\)</span> are maximally correlated.</p>
<p><span class="math display">\[
\hat{h_X}, \hat{h_Y} = \arg\max_{h_X, h_Y} corr(X h_X, Y h_Y)
\]</span></p>
<p>Why are we even interested in that? An example would be to compare the loadings in a pair of canonical vectors <span class="math inline">\(\hat{h_X}\)</span>, <span class="math inline">\(\hat{h_Y}\)</span> : Features from <span class="math inline">\(X\)</span> that have a high absolute loading in <span class="math inline">\(\hat{h_X}\)</span>, and features from <span class="math inline">\(Y\)</span> that have a high absolute loading in <span class="math inline">\(\hat{h_Y}\)</span> show some pattern of covariation because they might be based on the same latent factors (e.g. personality traits).</p>
</div>
<div id="classic-example" class="section level1">
<h1>Classic Example</h1>
<p>So get an intuition for CCA, we will look at a rather classical example.</p>
<div id="data-questions" class="section level2">
<h2>Data &amp; Questions</h2>
<p>We will download the questions that were used for the development of the Multidimensional Introversion-Extraversion Scales (see here: <a href="https://openpsychometrics.org/_rawdata" class="uri">https://openpsychometrics.org/_rawdata</a>).</p>
<p>The test contained 91 questions about the personality of the participants. We remove Q44 which is doubled.</p>
<pre class="r"><code>if (!any(str_detect(list.dirs(&quot;/mnt/sda/data&quot;, recursive = FALSE), 
           &quot;MIES_Dev_Data$&quot;))) {
  downloader::download(
  url=&quot;https://openpsychometrics.org/_rawdata/MIES_Dev_Data.zip&quot;,
  dest=&quot;/mnt/sda/data/MIES_DATA.zip&quot;, 
  mode=&quot;wb&quot;)
  unzip(&quot;/mnt/sda/data/MIES_DATA.zip&quot;, exdir = &quot;/mnt/sda/data/&quot;)
  unlink(&quot;/mnt/sda/data/MIES_DATA.zip&quot;)
}
mies_data &lt;- read_tsv(&quot;/mnt/sda/data/MIES_Dev_Data/data.csv&quot;, 
                      show_col_types = FALSE) %&gt;%
   dplyr::select(tidyselect::matches(&quot;Q[0-9]{1,2}A&quot;))
dim(mies_data)</code></pre>
<pre><code>## [1] 7188   91</code></pre>
<pre class="r"><code>q_raw &lt;- read_lines(&quot;/mnt/sda/data/MIES_Dev_Data/codebook.txt&quot;) %&gt;%
   `[`(., 10:100)
questions &lt;- tibble::tibble(
   q = paste0(str_extract(q_raw, &quot;Q[0-9]{1,2}&quot;), &quot;A&quot;),
   text = str_extract(q_raw, &#39;(?&lt;=: &quot;).+\\.&#39;)
)

#questions %&gt;%
#   filter(q %in% c(&quot;Q5A&quot;, &quot;Q44A&quot;))

questions &lt;- questions %&gt;% dplyr::filter(q != &quot;Q44A&quot;)
q_cleaned &lt;- mies_data[,1:91 != 44]

questions</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["q"],"name":[1],"type":["chr"],"align":["left"]},{"label":["text"],"name":[2],"type":["chr"],"align":["left"]}],"data":[{"1":"Q1A","2":"I would never audition to be on a game show."},{"1":"Q2A","2":"I am not much of a flirt."},{"1":"Q3A","2":"I have to psych myself up before I am brave enough to make a phone call."},{"1":"Q4A","2":"I would hate living with room mates."},{"1":"Q5A","2":"I mostly listen to people in conversations."},{"1":"Q6A","2":"I reveal little about myself."},{"1":"Q7A","2":"I spend hours alone with my hobbies."},{"1":"Q8A","2":"I prefer to eat alone."},{"1":"Q9A","2":"I have trouble finding people I want to be friends with."},{"1":"Q10A","2":"I prefer to socialize 1 on 1, than with a group."},{"1":"Q11A","2":"I sometimes speak so quietly people sometimes have trouble hearing me."},{"1":"Q12A","2":"I do not like to get my picture taken."},{"1":"Q13A","2":"I can keep a conversation going with anyone about anything."},{"1":"Q14A","2":"I want a huge social circle."},{"1":"Q15A","2":"I talk to people when waiting in lines."},{"1":"Q16A","2":"I act wild and crazy."},{"1":"Q17A","2":"I am a bundle of joy."},{"1":"Q18A","2":"I love excitement."},{"1":"Q19A","2":"I&apos;d like to be in a parade."},{"1":"Q20A","2":"I am a flamboyant person."},{"1":"Q21A","2":"I am good at making impromptu speeches."},{"1":"Q22A","2":"I naturally emerge as a leader."},{"1":"Q23A","2":"I am spontaneous."},{"1":"Q24A","2":"I would enjoy being a sports team coach."},{"1":"Q25A","2":"I have a strong personality."},{"1":"Q26A","2":"I am excited by many different activities."},{"1":"Q27A","2":"I spend most of my time in fantasy worlds."},{"1":"Q28A","2":"I often feel lucky."},{"1":"Q29A","2":"I don't make eye contact when I talk with people."},{"1":"Q30A","2":"I have a monotone voice."},{"1":"Q31A","2":"I am a touchy feely person."},{"1":"Q32A","2":"I would like to try bungee jumping."},{"1":"Q33A","2":"I tend to be admired by others."},{"1":"Q34A","2":"I make big physical movements whenever I get excited."},{"1":"Q35A","2":"I am brave."},{"1":"Q36A","2":"I am always in the moment."},{"1":"Q37A","2":"I am involved with my community."},{"1":"Q38A","2":"I am good an entertaining children."},{"1":"Q39A","2":"I like formal occasions."},{"1":"Q40A","2":"I would have to be lost for a very long time before asking help."},{"1":"Q41A","2":"I do not care about sports."},{"1":"Q42A","2":"I prefer individual sports to team sports."},{"1":"Q43A","2":"My parents know nothing about my love life."},{"1":"Q45A","2":"I never leave the door to my room open."},{"1":"Q46A","2":"I make a lot of hand motions when I talk."},{"1":"Q47A","2":"I take lots of pictures of my activities."},{"1":"Q48A","2":"When I was a child, I put on fake concerts and plays with my friends."},{"1":"Q49A","2":"I really like dancing."},{"1":"Q50A","2":"I would have difficulty describing myself to someone."},{"1":"Q51A","2":"My life would not make a good story."},{"1":"Q52A","2":"I am hesitant to give suggestions."},{"1":"Q53A","2":"I tire out quickly."},{"1":"Q54A","2":"I never tell people the important things about myself."},{"1":"Q55A","2":"I avoid going to unknown places."},{"1":"Q56A","2":"Going to the doctor is always awkward for me."},{"1":"Q57A","2":"I have not kept up with my old friends over the years."},{"1":"Q58A","2":"I have not been joyful for quite some time."},{"1":"Q59A","2":"I hate to ask for help."},{"1":"Q60A","2":"If I were to die, I would not want there to be a memorial for me."},{"1":"Q61A","2":"I hate shopping."},{"1":"Q62A","2":"I love to do impressions."},{"1":"Q63A","2":"I would be pleased if asked to speak at a funeral."},{"1":"Q64A","2":"I would never go to a dance club."},{"1":"Q65A","2":"I find it very hard to tell people I find them attractive."},{"1":"Q66A","2":"I hate people."},{"1":"Q67A","2":"I was an outcast in school."},{"1":"Q68A","2":"I would enjoy being a librarian."},{"1":"Q69A","2":"I am usually not single."},{"1":"Q70A","2":"I am able to stand up for myself."},{"1":"Q71A","2":"I would go surfing regularly if I lived on a beach."},{"1":"Q72A","2":"I have wanted to be a stand-up comedian."},{"1":"Q73A","2":"I am a high status person."},{"1":"Q74A","2":"I work out regularly."},{"1":"Q75A","2":"I laugh a lot."},{"1":"Q76A","2":"I like pranks."},{"1":"Q77A","2":"I am happy with my life."},{"1":"Q78A","2":"I am never at a loss for words."},{"1":"Q79A","2":"I feel healthy and vibrant most of the time."},{"1":"Q80A","2":"I love large parties."},{"1":"Q81A","2":"I am quiet around strangers."},{"1":"Q82A","2":"I don&#39;t talk a lot."},{"1":"Q83A","2":"I keep in the background."},{"1":"Q84A","2":"I don&#39;t like to draw attention to myself."},{"1":"Q85A","2":"I have little to say."},{"1":"Q86A","2":"I often feel blue."},{"1":"Q87A","2":"I am not really interested in others."},{"1":"Q88A","2":"I make people feel at ease."},{"1":"Q89A","2":"I don&#39;t mind being the center of attention."},{"1":"Q90A","2":"I start conversations."},{"1":"Q91A","2":"I talk to a lot of different people at parties."}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>For the sake of this tutorial we will randomly split the test into test A with the first 40 questions and test B with the last 50 questions.</p>
<pre class="r"><code>test_A &lt;- q_cleaned[,1:40]
test_B &lt;- q_cleaned[,41:90]</code></pre>
<p>So after all we have the following datasets <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<ul>
<li><p><span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span> with persons/observation <span class="math inline">\(g = 1,...N\)</span> (here: <span class="math inline">\(N=7188\)</span>) and questions <span class="math inline">\(Q^A_c\)</span> with <span class="math inline">\(c=1,...,M\)</span></p></li>
<li><p><span class="math inline">\(Y \in \mathbb{R}^{N \times P}\)</span> with persons/observation <span class="math inline">\(g = 1,...N\)</span> (here: <span class="math inline">\(N=7188\)</span>) and questions <span class="math inline">\(Q^B_d\)</span> with <span class="math inline">\(d=1,...,P\)</span></p></li>
</ul>
<p>And translating the CCA objective for this tasks, our goal is to find linear combinations of the columns of the questions scores from test A and the question scores from test B, such that the resulting vectors of length <span class="math inline">\(N\)</span> are maximally correlated.</p>
<p>In mathematical terms we seek to find the canonical correlation vectors <span class="math inline">\(\hat{h_X}\)</span> and <span class="math inline">\(\hat{h_Y}\)</span> such that <span class="math inline">\(X \hat{h_X}\)</span> and <span class="math inline">\(Y \hat{h_Y}\)</span> are maximally correlated.</p>
<p><span class="math display">\[
\hat{h_X}, \hat{h_Y} = \arg\max_{h_X, h_Y} corr(X h_X, Y h_Y)
\]</span></p>
<p>Thus, questions that get a high loading in <span class="math inline">\(\hat{h_X}\)</span> and questions that get a high loading in <span class="math inline">\(\hat{h_Y}\)</span> will be similar, meaning they query similar personality traits.</p>
<p>We can find <span class="math inline">\(min(M,P)\)</span> pairs of canonical correlation vectors as desribed below in the math section.</p>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>We will use the <code>CCA</code> package to perform the CCA analysis here.</p>
<pre class="r"><code>cca_out &lt;- stats::cancor(test_A, test_B)</code></pre>
<p>Looking at the distribution of the correlation coefficients.</p>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=1:length(cca_out$cor), y=cca_out$cor)) +
   labs(y = &quot;Correlation Coefficient&quot;, x = &quot;Index&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-6-1.png" width="576" /></p>
<div id="cc-vector" class="section level3">
<h3>1. CC Vector</h3>
<p>Checking which questions from A and which questions from B got a high loading in the first canonical correlation vector.</p>
<pre class="r"><code>qa &lt;- questions %&gt;% 
   left_join(tibble(q=names(cca_out$xcoef[,1]), xcoef1=cca_out$xcoef[,1],
                    xcoef2=cca_out$xcoef[,2], xcoef3=cca_out$xcoef[,3]),
             by=&quot;q&quot;) %&gt;%
   left_join(tibble(q=names(cca_out$ycoef[,1]), ycoef1=cca_out$ycoef[,1],
                    ycoef2=cca_out$ycoef[,2], ycoef3=cca_out$ycoef[,3]),
             by=&quot;q&quot;)
top_x &lt;- 3</code></pre>
<p>Top questions from test A:</p>
<pre class="r"><code>qa %&gt;% slice_max(order_by=xcoef1, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I reveal little about myself.&quot;              
## [2] &quot;I mostly listen to people in conversations.&quot;
## [3] &quot;I am not much of a flirt.&quot;</code></pre>
<p>Top questions from test B:</p>
<pre class="r"><code>qa %&gt;% slice_max(order_by=ycoef1, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I don&amp;#39;t talk a lot.&quot;      &quot;I keep in the background.&quot;   
## [3] &quot;I am quiet around strangers.&quot;</code></pre>
<p>Also looking at the questions in B with the most negative loading.</p>
<pre class="r"><code>qa %&gt;% slice_min(order_by=ycoef1, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I start conversations.&quot;                         
## [2] &quot;I talk to a lot of different people at parties.&quot;
## [3] &quot;I don&amp;#39;t mind being the center of attention.&quot;</code></pre>
<p>We can also compare the results if we were to perform linear regression for “Q13A” (“I can keep a conversation going with anyone about anything”) using the answers to all questions from test B as predictor.</p>
<pre class="r"><code>lm_res &lt;- lm(cbind(test_A[,&quot;Q13A&quot;], test_B), formula = Q13A ~ .)</code></pre>
<p>Again looking at the questions with the most positive coefficient.</p>
<pre class="r"><code>qa %&gt;%
   dplyr::filter(q %in% (lm_res$coefficients %&gt;% sort(decreasing=T) %&gt;% `[`(., 1:top_x) %&gt;% names)) %&gt;%
   dplyr::pull(text)</code></pre>
<pre><code>## [1] &quot;I am never at a loss for words.&quot; &quot;I make people feel at ease.&quot;    
## [3] &quot;I start conversations.&quot;</code></pre>
<p>And at the questions with the most negative coefficient.</p>
<pre class="r"><code>qa %&gt;%
   dplyr::filter(q %in% (lm_res$coefficients %&gt;% sort(decreasing=F) %&gt;% `[`(., 1:top_x) %&gt;% names)) %&gt;%
   dplyr::pull(text)</code></pre>
<pre><code>## [1] &quot;I am quiet around strangers.&quot; &quot;I don&amp;#39;t talk a lot.&quot;     
## [3] &quot;I have little to say.&quot;</code></pre>
</div>
<div id="cc-vector-1" class="section level3">
<h3>2. CC Vector</h3>
<pre class="r"><code>qa %&gt;% slice_max(order_by=xcoef2, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I reveal little about myself.&quot;                                   
## [2] &quot;I am brave.&quot;                                                     
## [3] &quot;I would have to be lost for a very long time before asking help.&quot;</code></pre>
<pre class="r"><code>qa %&gt;% slice_max(order_by=ycoef2, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I never tell people the important things about myself.&quot;
## [2] &quot;I am able to stand up for myself.&quot;                     
## [3] &quot;I don&amp;#39;t talk a lot.&quot;</code></pre>
</div>
<div id="cc-vector-2" class="section level3">
<h3>3. CC Vector</h3>
<pre class="r"><code>qa %&gt;% slice_max(order_by=xcoef3, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I am good at making impromptu speeches.&quot;                    
## [2] &quot;I have a strong personality.&quot;                               
## [3] &quot;I can keep a conversation going with anyone about anything.&quot;</code></pre>
<pre class="r"><code>qa %&gt;% slice_max(order_by=ycoef3, n=top_x) %&gt;% pull(text)</code></pre>
<pre><code>## [1] &quot;I am never at a loss for words.&quot; &quot;I hate people.&quot;                 
## [3] &quot;I do not care about sports.&quot;</code></pre>
</div>
</div>
</div>
<div id="solution-via-svd" class="section level1">
<h1>Solution via SVD</h1>
<ul>
<li><p>Given <span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span> with observations <span class="math inline">\(g = 1,...N\)</span> and features <span class="math inline">\(Q^A_c\)</span> with <span class="math inline">\(c=1,...,M\)</span></p></li>
<li><p>And <span class="math inline">\(Y \in \mathbb{R}^{N \times P}\)</span> with the same observations <span class="math inline">\(g = 1,...N\)</span> and different features <span class="math inline">\(Q^B_d\)</span> with <span class="math inline">\(d=1,...,P\)</span></p></li>
<li><p>We seek to find <span class="math inline">\(\hat{h_X}\)</span> and <span class="math inline">\(\hat{h_Y}\)</span> (for now only first pair of canonical correlation vectors)</p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}, \hat{h_Y} &amp;= \arg\max_{h_X, h_Y} corr(X h_X, Y h_Y) \\
 &amp;= \arg\max_{h_X, h_Y} 
 \frac{Cov(X h_X, Y h_Y)}{\sqrt{V(X h_X)} \sqrt{V(Y h_Y)}}
\end{align*}
\]</span></p>
<ul>
<li><p>We call <span class="math inline">\(z_X = X h_X\)</span> and <span class="math inline">\(z_Y = Y h_Y\)</span> the first pair of canonical variables.</p></li>
<li><p>We will columns of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are centered (so the mean for each feature is 0)</p></li>
</ul>
<p><span class="math display">\[
\mathbb{E}[X_{:,c}] = 0 \quad \forall c=1,...,M
\]</span></p>
<ul>
<li>Thus allows us to rewrite the correlation using inner products (or more specifically the dot product). Also not that this holds true because if <span class="math inline">\(X, Y\)</span> are centered, <span class="math inline">\(z_X, z_Y\)</span> will be centered.</li>
</ul>
<p><span class="math display">\[
\begin{align*}
corr(x,y) &amp;= \frac{Cov(x,y)}{\sqrt{V(x)} \sqrt{V(y)}} \\
&amp;= \frac{\frac{1}{N} \sum_{i=1}^N(x_i-\bar{x})(y_i-\bar{y})^T}{\sqrt{\frac{1}{N} \sum_{i=1}^N(x_i-\bar{x})(x_i-\bar{x})^T} \sqrt{\frac{1}{N} \sum_{i=1}^N(y_i-\bar{y})(y_i-\bar{y})^T}} \\
&amp;= \frac{\sum_{i=1}^Nx_i y_i^T}{\sqrt{ \sum_{i=1}^Nx_i x_i^T} \sqrt{ \sum_{i=1}^Nxy_i y_i^T}} \\
&amp;= \frac{x^Ty}{\sqrt{x^Tx}\sqrt{y^Ty}} \\
&amp;= \frac{\langle x,y \rangle}{\|x\|\|y\|}
\end{align*}
\]</span></p>
<ul>
<li>Thus we can rewrite the above equation:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}, \hat{h_Y} &amp;= \arg\max_{h_X, h_Y} 
\frac{Cov(X h_X, Y h_Y)}{\sqrt{V(X h_X)} \sqrt{V(Y h_Y)}} \\
&amp;= \arg\max_{h_X, h_Y} \frac{(Xh_x)^T(Yh_y)}{\sqrt{(Xh_x)^T(Xh_x)}\sqrt{(Yh_y)^T(Yh_y)}} \\
&amp;= \arg\max_{h_X, h_Y} \frac{(Xh_x)^T(Yh_y)}{\|Xh_x\|_2\|Yh_y\|_2}
\end{align*}
\]</span></p>
<ul>
<li>Since the correlation is scale invariant, we constrain the solution using</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}, \hat{h_Y}
&amp;= \arg\max_{h_X, h_Y} (Xh_x)^T(Yh_y) \quad s.t. \; \|Xh_x\|_2=1, \; \|Yh_y\|_2 = 1
\end{align*}
\]</span></p>
<ul>
<li>The above equation holds true for the first pair of canonical vectors, but for the subsequent pairs, we require that the <span class="math inline">\(k\)</span>’th canonical variables <span class="math inline">\(Xh_x^{(k)}= z_x^{(k)} \in \mathbb{R}^N\)</span>, <span class="math inline">\(Yh_y^{(k)}= z_y^{(k)} \in \mathbb{R}^N\)</span> are orthogonal to all <span class="math inline">\((k-1)\)</span> pairs. This ensures that the canonical variables capture different axes of covariation.</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}^{(k)}, \hat{h_Y}^{(k)}
= \arg\max_{h_X, h_Y} (Xh_x)^T(Yh_y) \quad s.t. &amp; \; \|Xh_x\|_2=1, \; \|Yh_y\|_2 = 1 \\
&amp; (Xh_X^{(k)})^T(Xh_X^{(j)}) = 0 \; \forall \; j=1,...,k-1 \\
&amp; (Yh_Y^{(k)})^T(Yh_Y^{(j)}) = 0 \; \forall \; j=1,...,k-1
\end{align*}
\]</span></p>
<ul>
<li>Given that <span class="math inline">\(N \geq M\)</span> and <span class="math inline">\(N \geq P\)</span>, the total number of canonical directions (pairs of canonical vectors) is limited by the rank of <span class="math inline">\(X\)</span> of <span class="math inline">\(Y\)</span>, we define the maximum number of directions as</li>
</ul>
<p><span class="math display">\[
R = \min\{ rk(X), rk(Y) \}
\]</span></p>
<ul>
<li><p>To solve the objective we transform the problem by "sphering of the centered matrices <span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span> and <span class="math inline">\(Y \in \mathbb{R}^{N \times P}\)</span>. Therefore, we first introduce the scatter matrices <span class="math inline">\(S_X = X^TX\)</span>, <span class="math inline">\(S_Y = Y^T Y\)</span>.</p></li>
<li><p>Assuming that <span class="math inline">\(rk(X) = M\)</span> and <span class="math inline">\(rk(Y) = P\)</span>, <span class="math inline">\(S_X\)</span>, <span class="math inline">\(S_Y\)</span> are symmetric, positivie (semi)-definite, and thus we can factorize them into the non-negative square roots (similar to the cholesky decomposition):</p></li>
</ul>
<p><span class="math display">\[
S_X = S_X^{1/2} S_X^{1/2}, \quad S_Y = S_Y^{1/2} S_Y^{1/2}
\]</span></p>
<ul>
<li>Now we can “sphere” our matrices <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> via</li>
</ul>
<p><span class="math display">\[
\tilde{X} = X S_X^{-1/2}, \tilde{Y} = Y S_Y^{-1/2}
\]</span></p>
<ul>
<li>This is called “sphering” because the covariance of <span class="math inline">\(\tilde{X}\)</span> and <span class="math inline">\(\tilde{Y}\)</span> are scaled identity matrices (assuming that <span class="math inline">\(\tilde{X}\)</span> is still centered):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
cov(\tilde{X}) &amp;= cov(X S_X^{-1/2}) \\
&amp;= \frac{1}{N}(X S_X^{-1/2})^T(X S_X^{-1/2}) \\
&amp;= \frac{1}{N} (S_X^{-1/2})^T X^T X S_X^{-1/2} \\
&amp;= \frac{1}{N} S_X^{-1/2} S_X S_X^{-1/2} \\
&amp;= \frac{1}{N} I
\end{align*}
\]</span></p>
<ul>
<li>The objective (for the first pair of canonical vectors) becomes:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\tilde{\hat{h_X}}, \tilde{\hat{h_Y}} &amp;= \arg\max_{\tilde{h_X}, \tilde{h_Y}} 
(\tilde{X} \tilde{h_X})^T(\tilde{Y} \tilde{h_Y}) \quad s.t. &amp; \; \|\tilde{X} \tilde{h_X}\|_2=1, \; \|\tilde{Y} \tilde{h_Y}\|_2 = 1
\end{align*}
\]</span></p>
<ul>
<li>where <span class="math inline">\(h_X\)</span> and <span class="math inline">\(h_Y\)</span> can be transformed back via</li>
</ul>
<p><span class="math display">\[
h_X = S_X^{-1/2}\tilde{h_X}, \quad h_Y = S_Y^{-1/2}\tilde{h_Y}
\]</span></p>
<ul>
<li>Additionally, we can simplify the above formula using</li>
</ul>
<p><span class="math display">\[
\begin{align*}
 \|\tilde{X} \tilde{h_X}\|_2 &amp;= \sqrt{ (\tilde{X} \tilde{h_X})^T(\tilde{X} \tilde{h_X})} \\
 &amp;= \sqrt{ \tilde{h_X}^T \tilde{X}^T \tilde{X} \tilde{h_X}} \\
 &amp;=  \sqrt{ \tilde{h_X}^T S_X^{-1/2} X^T X S_X^{-1/2} \tilde{h_X}} \\
 &amp;= \sqrt{\tilde{h_X}^T \tilde{h_X}} \\
 &amp;= \| \tilde{h_X} \|_2
\end{align*}
\]</span></p>
<ul>
<li>Thus, we get the new objective</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\tilde{\hat{h_X}}, \tilde{\hat{h_Y}} &amp;= \arg\max_{\tilde{h_X}, \tilde{h_Y}} 
(\tilde{X} \tilde{h_X})^T(\tilde{Y} \tilde{h_Y}) \quad s.t. &amp; \; \|\tilde{h_X}\|_2=1, \; \|\tilde{h_Y}\|_2 = 1 \\
&amp;= \arg\max_{\tilde{h_X}, \tilde{h_Y}} 
\tilde{h_X}^T \tilde{X}^T \tilde{Y} \tilde{h_Y} \quad s.t. &amp; \; \|\tilde{h_X}\|_2=1, \; \|\tilde{h_Y}\|_2 = 1 \\
\end{align*}
\]</span></p>
<ul>
<li>We can solve this transformed objective via SVD of <span class="math inline">\(K = \tilde{X}^T \tilde{Y} \in \mathbb{R}^{M \times P}\)</span> (using the full SVD here, we get):</li>
</ul>
<p><span class="math display">\[
\tilde{X}^T \tilde{Y} = U \Sigma V^T \quad \text{with} \quad U \in \mathbb{R}^{M \times M}, \Sigma \in \mathbb{R}^{M \times P}, V \in \mathbb{R}^{P \times P}
\]</span></p>
<ul>
<li><span class="math inline">\(U\)</span>, <span class="math inline">\(V\)</span> are orthogonal, meaning it’s columns (<span class="math inline">\(u_i\)</span>, <span class="math inline">\(v_i\)</span>) are orthonormal:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; u_i^T u_j = 0 \quad \text {for } i \neq j \\
&amp; u_i^T u_i = 1
\end{aligned}
\]</span></p>
<ul>
<li><p><span class="math inline">\(\Sigma\)</span> contains the singular values in sorted order on its diagonal such that <span class="math inline">\(\sigma_1 &gt; \sigma_2 &gt; ... &gt; \sigma_R\)</span>.</p></li>
<li><p>Given that <span class="math inline">\(h_X = S_X^{-1/2}\tilde{h_X}\)</span>, <span class="math inline">\(h_Y = S_Y^{-1/2}\tilde{h_Y}\)</span> and <span class="math inline">\(\tilde{h_X} = u_i\)</span>, <span class="math inline">\(\tilde{h_Y} = v_i\)</span>, the canonical vectors are given by</p></li>
</ul>
<p><span class="math display">\[
h_X^{(i)} = S_X^{-1/2} \tilde{h_X^{(i)}} = S_X^{-1/2} u_i \quad \text{for } i=1,...,R \\
h_Y^{(i)} = S_X^{-1/2} \tilde{h_Y^{(i)}}  = S_Y^{-1/2} v_i \quad \text{for } i=1,...,R
\]</span></p>
<ul>
<li>The canonical correlations corresponds to</li>
</ul>
<p><span class="math display">\[
\rho^{(i)} = \sigma_i \quad \text{for } i=1,...,R
\]</span></p>
<ul>
<li>Looking at the original objective</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}^{(k)}, \hat{h_Y}^{(k)}
= \arg\max_{h_X, h_Y} (Xh_x)^T(Yh_y) \quad s.t. &amp; \; \|Xh_x\|_2=1, \; \|Yh_y\|_2 = 1 \\
&amp; (Xh_X^{(k)})^T(Xh_X^{(j)}) = 0 \; \forall \; j=1,...,k-1 \\
&amp; (Yh_Y^{(k)})^T(Yh_Y^{(j)}) = 0 \; \forall \; j=1,...,k-1
\end{align*}
\]</span></p>
<ul>
<li>We can validate that the constrains are fulfilled (the canonical variables <span class="math inline">\(z_X^{(i)}\)</span>, <span class="math inline">\(z_X^{(j)}\)</span> are orthonormal, because <span class="math inline">\(v_i\)</span>, <span class="math inline">\(v_j\)</span> are orthonormal by construction of the SVD).</li>
</ul>
<p><span class="math display">\[
\begin{align*}
(z_X^{(i)})^T z_X^{(j)} &amp;= (Xh_X^{(i)})^T (Xh_X^{(j)}) \\
&amp;= (h_X^{(i)})^T X^T X h_X^{(j)} \\
&amp;= (S_X^{-1/2} \tilde{h_X^{(i)}})^T S_X ( S_X^{-1/2} \tilde{h_X^{(j)}}) \\
&amp;= (\tilde{h_X^{(i)}})^T S_X^{-1/2} S_X S_X^{-1/2} \tilde{h_X^{(j)}} \\
&amp;=  (\tilde{h_X^{(i)}})^T \tilde{h_X^{(j)}} \\
&amp;= v_i^T v_j
\end{align*}
\]</span></p>
</div>
<div id="implementation-from-scratch" class="section level1">
<h1>Implementation from Scratch</h1>
<pre class="r"><code>#X &lt;- as.matrix(test_A)
#Y &lt;- as.matrix(test_B)
compute_cca &lt;- function(X, Y, scale=FALSE) {
   
   R = min(ncol(X), ncol(Y))
   
   # centering and scaling
   X_centered &lt;- t( t(X) - Matrix::colMeans(X) )
   Y_centered &lt;- t( t(Y) - Matrix::colMeans(Y) )
   
   if (scale) {
      X_centered &lt;- t( t(X_centered) /  matrixStats::colSds(X_centered) )
      Y_centered &lt;- t( t(Y_centered) /  matrixStats::colSds(Y_centered) )
   }
   
   # get the scatter matrix
   Sx &lt;- t(X_centered) %*% X_centered
   Sy &lt;- t(Y_centered) %*% Y_centered
   
   # factorize into square root spd matrices
   Sx_eigen &lt;- eigen(Sx)
   Sx_sqrt &lt;- Sx_eigen$vectors %*% diag(sqrt(Sx_eigen$values)) %*% 
      solve(Sx_eigen$vectors)
   Sy_eigen &lt;- eigen(Sy)
   Sy_sqrt &lt;- Sy_eigen$vectors %*% diag(sqrt(Sy_eigen$values)) %*% 
      solve(Sy_eigen$vectors)
   stopifnot(all(dplyr::near(Sx_sqrt %*% Sx_sqrt, Sx)))
   stopifnot(all(dplyr::near(Sy_sqrt %*% Sy_sqrt, Sy)))
   
   # compute the inverse
   Sx_sqrt_inv &lt;- solve(Sx_sqrt)
   Sy_sqrt_inv &lt;- solve(Sy_sqrt)
   
   # compute K and its singular value decomposition
   K = t(X_centered%*%Sx_sqrt_inv) %*% (Y_centered%*%Sy_sqrt_inv)
   svd_res &lt;- svd(K, nu = ncol(X), nv = ncol(Y))
   
   # get the left and right canonical vectors
   hxs &lt;- Sx_sqrt_inv %*% svd_res$u
   hys &lt;- Sy_sqrt_inv %*% svd_res$v
   
   # compute the left and right canonical variables
   zxs &lt;- X_centered %*% hxs
   zys &lt;- Y_centered %*% hys
   
   # check that the canonical variables are orthonormal
   stopifnot(
      all(dplyr::near(t(zxs[,1]) %*% zxs[,2], 0),
       dplyr::near(t(zys[,1]) %*% zys[,2], 0))
   )
   
   # check that the correlations and the singular values corresponds
   stopifnot(
      dplyr::near(purrr::map_dbl(1:ncol(zxs), ~ stats::cor(zxs[,.x], zys[,.x])),
                  svd_res$d)
   )
   
   return(list(cor = svd_res$d, xcoef = hxs, ycoef = hys, R = R))
}</code></pre>
<p>Testing and comparing the function. For the proper canonical variables, the results are the same.</p>
<pre class="r"><code>test &lt;- compute_cca(as.matrix(test_A), as.matrix(test_B))
all(dplyr::near(test$cor, cca_out$cor))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>all(dplyr::near(abs(test$xcoef[,1:test$R]), abs(cca_out$xcoef[,1:test$R])))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>all(dplyr::near(abs(test$ycoef[,1:test$R]), abs(cca_out$ycoef[,1:test$R])))</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="application-to-single-cell-data" class="section level1">
<h1>Application to Single-Cell Data</h1>
<p>Here will assume that we only have two datasets <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> which we would like to integrate.</p>
<p>In the first setting (see here), we will assume that we have two scRNA-seq datasets which we would like to integrate. More specifically we want to adjust the count matrix of the second dataset <span class="math inline">\(Y\)</span>, such that the datasets are aligned.</p>
<p>In the second case (see here), our task will be two integrate one scRNA-seq with an scATAC-seq datasets. More specifically, we want to transfer the counts from the scRNA-seq data as well as the celltype labels to the scATAC data, such that we can later on link peaks-to-genes via correlation of peak accessibility to gene expression.</p>
<p>We focus here on the implementation by Seurat (V3). <span class="citation">(<a href="#ref-10.1038/nbt.4096" role="doc-biblioref"><em>2</em></a>, <a href="#ref-10.1016/j.cell.2019.05.031" role="doc-biblioref"><em>3</em></a>)</span> To that end, we will use CCA to create a common embedding for the reference <span class="math inline">\(X\)</span> and the query <span class="math inline">\(Y\)</span>, such that we can find cells in both datasets that corresponds to each other, which we call “Ankers.” How we use these “Anchors” to align the datasets will be further described in () and ().</p>
<p>Using a similar notation as above, we say that <span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span> has <span class="math inline">\(N\)</span> features/genes and <span class="math inline">\(M\)</span> cells, whereas <span class="math inline">\(Y \in \mathbb{R}^{N \times P}\)</span> has <span class="math inline">\(P\)</span> cells and the same <span class="math inline">\(N\)</span> features.</p>
<p>Given that we typcially use the highly variable genes, so about 2000-3000 features, the number of features <span class="math inline">\(N\)</span> is much smaller than the number of cells <span class="math inline">\(M\)</span>, <span class="math inline">\(P\)</span>:</p>
<p><span class="math display">\[
N &lt; M, \quad N &lt; P
\]</span></p>
<p>Thus the rank <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is max <span class="math inline">\(N\)</span>, using the fact that <span class="math inline">\(rank(X^t X) = rank(X)\)</span>, we get that the max rank of <span class="math inline">\(S_X = X^T X \in \mathbb{R}^{M \times M}\)</span> is <span class="math inline">\(N\)</span> (as it is for <span class="math inline">\(Y\)</span>) (see for example here: <a href="https://math.stackexchange.com/questions/2807892/prove-that-textrankxtx-textrankx" class="uri">https://math.stackexchange.com/questions/2807892/prove-that-textrankxtx-textrankx</a>). This also means that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> will not be invertible and thus we cannot used the solution as written above.</p>
<p>In other terms the problem becomes underdetermined and we need some kind of regularization (but we need to make sure not to promote sparsity too much!). One way, is to delete all off-diagonal terms in <span class="math inline">\(S_X\)</span> and <span class="math inline">\(S_Y\)</span> (“diagonal penalized CCA”), such that we ensure that they are rank <span class="math inline">\(M\)</span> or rank <span class="math inline">\(P\)</span> respectively. <span class="citation">(<a href="#ref-10.1093/biostatistics/kxp008" role="doc-biblioref"><em>1</em></a>)</span>.</p>
<p>If we scale <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> before, such that the variance of each column is 1, the scatter matrices <span class="math inline">\(S_X\)</span>, <span class="math inline">\(S_Y\)</span> will be scaled identity matrices.</p>
<p><span class="math display">\[
S_X = N * I \in \mathbb{R}^{M \times M}, \quad S_Y = N * I \in \mathbb{R}^{P \times P}
\]</span></p>
<p>Thus, the CCA objective becomes</p>
<p><span class="math display">\[
\begin{align*}
\hat{h_X}^{(k)}, \hat{h_Y}^{(k)}
= \arg\max_{h_X, h_Y} (Xh_x)^T(Yh_y) \quad s.t. &amp; \; \|h_x\|_2=1, \; \|h_y\|_2 = 1 \\
&amp; (h_X^{(k)})^T(h_X^{(j)}) = 0 \; \forall \; j=1,...,k-1 \\
&amp; (h_Y^{(k)})^T(h_Y^{(j)}) = 0 \; \forall \; j=1,...,k-1
\end{align*}
\]</span></p>
<p>Which we can solve similarly via the SVD of <span class="math inline">\(X^T Y\)</span>:</p>
<p><span class="math display">\[
X^T Y = U \Sigma V^T \quad \text{with} \quad U \in \mathbb{R}^{M \times M}, \Sigma \in \mathbb{R}^{M \times P}, V \in \mathbb{R}^{P \times P}
\]</span></p>
<p>Given that <span class="math inline">\(h_X = S_X^{-1/2}\tilde{h_X}\)</span>, <span class="math inline">\(h_Y = S_Y^{-1/2}\tilde{h_Y}\)</span> and <span class="math inline">\(\tilde{h_X} = u_i\)</span>, <span class="math inline">\(\tilde{h_Y} = v_i\)</span>, the canonical vectors are given by</p>
<p><span class="math display">\[
h_X^{(i)} = u_i \quad \text{for } i=1,...,R \\
h_Y^{(i)} = v_i \quad \text{for } i=1,...,R
\]</span></p>
<p>Furthermore, we do not have to solve the full SVD, but we can approximate the first <span class="math inline">\(k\)</span> singular values/vectors using the augmented implicitly restarted Lanczos bidiagonalization algorithm which is implemented in <code>irlba</code>.</p>
<p>Lastly, we need to control for global differences in scale (what exactly does that mean?).</p>
<p>Previously in Butler et al. (2018) <span class="citation">(<a href="#ref-10.1038/nbt.4096" role="doc-biblioref"><em>2</em></a>)</span>, the pairs of canonical vectors <span class="math inline">\(h_{X}^{(i)}\)</span> and <span class="math inline">\(h_{Y}^{(i)}\)</span> we aligned by computing a metagene using a linear combination of the 30 genes with the highest biweight midcorrelation (bicor) to <span class="math inline">\(h_{X}^{(i)}\)</span> and <span class="math inline">\(h_{Y}^{(i)}\)</span>. Now have each cell in <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> laying in a 30-dimensional space defined by the metagene. Lastly, to align the cells dynamic time warping (DTW) is used, which places a cell as close as possible to the most similar cell in the other dataset while maintaining the relative ordering of the cells. Now the same dynamic time warping is applied to the canonical correlation vectors leading a common aligned scale. This procedure is applied to all canonical vectors <span class="math inline">\(h_{X}^{(i)}\)</span> and <span class="math inline">\(h_{Y}^{(i)}\)</span> with <span class="math inline">\(i=1,...,k\)</span>.</p>
<p>However, in Stuart et al. (2019) <span class="citation">(<a href="#ref-10.1016/j.cell.2019.05.031" role="doc-biblioref"><em>3</em></a>)</span> the procedure was simplified. To correct for global difference in scale between the two different datasets L2 normalization is used on the cell embeddings. Assuming that <span class="math inline">\(A_i\)</span> is the the coordinate vector for a cell <span class="math inline">\(i\)</span> such that <span class="math inline">\(|A| = k\)</span>, we normalize the coordinates using:</p>
</div>
<div id="integration-of-2-scrna-datasets" class="section level1">
<h1>Integration of 2 scRNA datasets</h1>
<div id="data" class="section level2">
<h2>Data</h2>
<p>We will integrate two cov19 samples.</p>
<pre class="r"><code>rna_list &lt;- readRDS(&quot;cov19_balf_gex_qc_output/2022-04-10-11-26_rna_list_filtered.RDS&quot;) %&gt;%
   `[`(., c(&quot;HC1&quot;, &quot;HC2&quot;, &quot;S1&quot;, &quot;S2&quot;))</code></pre>
<p>Add the sample names as prefix.</p>
<pre class="r"><code>rna_list &lt;- purrr::imap(rna_list, function(mtx, smp) {
   colnames(mtx) &lt;- paste0(smp, &quot;_&quot;, colnames(mtx))
   mtx })</code></pre>
<p>Next we will remove all genes which have 0 variance in at least one sample.</p>
<pre class="r"><code>genes_to_remove &lt;- 
   purrr::map_dfc(rna_list, function(mtx) {
   sparseMatrixStats::rowVars(mtx)
}) %&gt;%
   mutate(across(everything(), function(x) x == 0)) %&gt;%
   apply(., 1, any) %&gt;%
   `[`(rownames(rna_list$HC1), .)
genes_to_remove</code></pre>
<pre><code>##  [1] &quot;RAD54L&quot;     &quot;BNIPL&quot;      &quot;WNT9A&quot;      &quot;ANKRD20A8P&quot; &quot;LEF1&quot;      
##  [6] &quot;SERPINB9P1&quot; &quot;FBXL13&quot;     &quot;STRIP2&quot;     &quot;SCARA3&quot;     &quot;ABO&quot;       
## [11] &quot;CUBN&quot;       &quot;AC079174.2&quot; &quot;FITM1&quot;      &quot;NFATC4&quot;     &quot;MCTP2&quot;     
## [16] &quot;ERN2&quot;       &quot;CX3CL1&quot;     &quot;PIEZO2&quot;     &quot;CERS4&quot;</code></pre>
<pre class="r"><code>rna_list &lt;- purrr::map(rna_list, ~ .x[!rownames(.x) %in% genes_to_remove,])</code></pre>
<p>Defining some helper functions.</p>
<pre class="r"><code>log_norm &lt;- function(mtx, sf=1e4) {
   log1p(
      t( t(mtx) / sparseMatrixStats::colSums2(mtx) ) * sf
   )
}

hvg_vst_method &lt;- function(mtx, plotting=F) {
   df &lt;- tibble(gene = rownames(mtx), 
                mean = Matrix::rowMeans(mtx),
                var = sparseMatrixStats::rowVars(mtx)) %&gt;%
      mutate(log10.mean = log10(mean), 
             log10.var = log10(var)) %&gt;%
     filter(is.finite(log10.var))
   l.fit &lt;- stats::loess(formula = log10.var ~ log10.mean, data = df, span = 0.3)
   df &lt;- df %&gt;%
     mutate(pred.log10.var = predict(l.fit, log10.mean)) %&gt;%
     mutate(pred.var = 10^pred.log10.var)
   if (plotting) {
      p &lt;- 
         ggplot() +
        geom_point(aes(x=df$log10.mean, y=df$log10.var),
                   size = 0.2)  +
        geom_line(aes(x=df$log10.mean, y=l.fit$fitted), color = &quot;blue&quot;) +
        labs(x = &quot;log10 Mean&quot;, y = &quot;log10 Variance&quot;, 
             title = &quot;Loess Fit&quot;) +
        scale_color_manual(values = c(&quot;TRUE&quot; = &quot;forestgreen&quot;, &quot;FALSE&quot; = &quot;red&quot;)) +
        coord_equal()
      print(p)
   }
   gene_mean_subtracted &lt;- mtx - df$mean
   exp_var_divided &lt;- gene_mean_subtracted / (df$pred.var)^0.5
   clip &lt;- ncol(mtx)^0.5
   exp_var_divided[exp_var_divided &gt; clip] &lt;- clip
   exp_var_divided &lt;- Matrix::Matrix(exp_var_divided, sparse=TRUE)
   
   df &lt;- df %&gt;%
     mutate(std.var = sparseMatrixStats::rowVars(exp_var_divided))
   if (plotting) {
      p &lt;- 
         df %&gt;%
           ggplot() +
           geom_point(aes(x=log10.mean, y=std.var),
                      size = 0.2, alpha = 0.5) +
           labs(x = &quot;log10 Mean Expression&quot;, y = &quot;Standardized Variance&quot;, 
                title = &quot;Standardized Variance&quot;) +
           scale_color_manual(values = c(&quot;TRUE&quot; = &quot;forestgreen&quot;, &quot;FALSE&quot; = &quot;red&quot;)) +
           guides(colour = guide_legend(override.aes = list(size = 2)))
      print(p)
   }
   df
}</code></pre>
<p>Get the union of the 1500 most highly variable genes from both samples determined by the <code>vst-method</code>.</p>
<pre class="r"><code>hvg &lt;- purrr::map(rna_list, function(mtx) {
   df &lt;- hvg_vst_method(mtx) %&gt;%
      dplyr::slice_max(std.var, n=1500) %&gt;%
      pull(gene)
}) %&gt;%
   unlist() %&gt;%
   unique()
length(hvg)</code></pre>
<pre><code>## [1] 2853</code></pre>
<p>Now we will check for batch effects by looking at the first principal components and a UMAP.</p>
<pre class="r"><code>pca &lt;- do.call(cbind, rna_list) %&gt;%
   log_norm() %&gt;% 
   .[hvg,] %&gt;%
   t() %&gt;%
   irlba::prcomp_irlba(., n=30, retx=TRUE,
                       center=TRUE, scale. = TRUE)
plot(pca$sdev)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=pca$x[,1], y=pca$x[,2],
                  color = str_extract(colnames(do.call(cbind, rna_list)),
                                     &quot;S[0-9]|HC[0-9]&quot;)),
              size=0.1, alpha=0.5) +
   labs(color=&quot;Sample&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>And what about the umap?</p>
<pre class="r"><code>umap &lt;- uwot::umap(pca$x)</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=umap[,1], y=umap[,2],
                  color = str_extract(colnames(do.call(cbind, rna_list)),
                                     &quot;S[0-9]|HC[0-9]&quot;)),
              size=0.1, alpha=0.1) +
   labs(color=&quot;Sample&quot;) +
   guides(color = guide_legend(override.aes = list(size = 2,
                                                   alpha=1)))</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>So we do see a very strong batch effect and we might first integrate the two healthy samples.</p>
<pre class="r"><code>pca &lt;- do.call(cbind, rna_list[c(&quot;HC1&quot;, &quot;HC2&quot;)]) %&gt;%
   log_norm() %&gt;% 
   .[hvg,] %&gt;%
   t() %&gt;%
   irlba::prcomp_irlba(., n=30, retx=TRUE,
                       center=TRUE, scale. = TRUE)
plot(pca$sdev)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=pca$x[,1], y=pca$x[,2],
                  color = str_extract(colnames(do.call(cbind, rna_list[c(&quot;HC1&quot;, &quot;HC2&quot;)])), &quot;S[0-9]|HC[0-9]&quot;)),
              size=0.1, alpha=0.5) +
   labs(color=&quot;Sample&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>And what about the umap?</p>
<pre class="r"><code>umap &lt;- uwot::umap(pca$x)</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=umap[,1], y=umap[,2],
                  color = str_extract(colnames(do.call(cbind, rna_list[c(&quot;HC1&quot;, &quot;HC2&quot;)])),
                                     &quot;S[0-9]|HC[0-9]&quot;)),
              size=0.1, alpha=0.1) +
   labs(color=&quot;Sample&quot;) +
   guides(color = guide_legend(override.aes = list(size = 2,
                                                   alpha=1)))</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>We might also check where we have which genes.</p>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=umap[,1], y=umap[,2],
                  color = do.call(cbind, rna_list[c(&quot;HC1&quot;, &quot;HC2&quot;)])[&quot;CD68&quot;,] &gt; 5),
              size=0.1, alpha=1) +
   labs(color=&quot;CD68 Expressedxpressed&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
<div id="cca" class="section level2">
<h2>CCA</h2>
<p>We will first try to integrate the two healthy samples above (HC1 and HC2).</p>
<p>We will use the highly variable genes as computed above.</p>
<pre class="r"><code>length(hvg)</code></pre>
<pre><code>## [1] 2853</code></pre>
<p>Center and scale the matrices.</p>
<pre class="r"><code>#X &lt;- rna_list$HC1[hvg,]
#Y &lt;- rna_list$HC2[hvg,]
compute_cca &lt;- function(X, Y, k=30, scale=TRUE) {
   
   # centering and scaling
   X_centered &lt;- MatrixExtra::as.csc.matrix( t( t(X) - Matrix::colMeans(X) ) )
   Y_centered &lt;- MatrixExtra::as.csc.matrix( t( t(Y) - Matrix::colMeans(Y) ) )
   
   if (scale) {
      X_centered &lt;- t( t(X_centered) /  sparseMatrixStats::colSds(X_centered) )
      Y_centered &lt;- t( t(Y_centered) /  sparseMatrixStats::colSds(Y_centered) )
   }
   
   # compute K and its singular value decomposition
   K = t(X_centered) %*% (Y_centered)
   
   svd_res &lt;- irlba::svdr(x=K, k=k)
   
   return(list(cor = svd_res$d, xcoef = svd_res$u, ycoef = svd_res$v))
}</code></pre>
<pre class="r"><code>cca.out &lt;- compute_cca(rna_list$HC1[hvg,], rna_list$HC2[hvg,])</code></pre>
<pre class="r"><code>cca.out$cor %&gt;% length</code></pre>
<pre><code>## [1] 30</code></pre>
<pre class="r"><code>cca.out$xcoef %&gt;% dim</code></pre>
<pre><code>## [1] 7342   30</code></pre>
<pre class="r"><code>cca.out$ycoef %&gt;% dim</code></pre>
<pre><code>## [1] 7320   30</code></pre>
<p>Lastly we need to apply the L2 penalty to each row (i.e. the embedding of a cell).</p>
<pre class="r"><code>embed_x &lt;- cca.out$xcoef / sqrt(Matrix::rowSums(cca.out$xcoef^2))
embed_y &lt;- cca.out$ycoef / sqrt(Matrix::rowSums(cca.out$ycoef^2))
rownames(embed_x) &lt;- colnames(rna_list$HC1[hvg,])
rownames(embed_y) &lt;- colnames(rna_list$HC2[hvg,])</code></pre>
<p>Let’s compute a umap and look at the data. And they look pretty aligned!</p>
<pre class="r"><code>umap &lt;- uwot::umap(rbind(embed_x, embed_y))</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=umap[,1], y=umap[,2],
                  color = str_extract(rownames(rbind(embed_x, embed_y)),
                                      &quot;HC[0-9]|M[0-9]|S[0-9]&quot;)),
              size=0.2, alpha=0.2) +
   labs(color=&quot;Sample&quot;) +
   guides(color = guide_legend(override.aes = list(size = 2,
                                                   alpha=1)))</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
</div>
<div id="transfer-anchors" class="section level2">
<h2>Transfer Anchors</h2>
<p>In our common CCA embedding we search for mutual nearest neighbors, e.g. assuming <code>k.anchor=10</code>, cell A and cell B are MNNs if cell A is among the 10 nearest neighbors of cell B, and cell B is among the 10 nearest neighbors of cell A. We call these pairs of cell <code>TransferAnchors</code>.</p>
<p>So in the example below A and B are MNN. B is the closest cell for C, but the are not MNN (here assuming that <code>k.anchor=1</code>)</p>
<pre class="r"><code>suppressPackageStartupMessages(library(tidyverse))
tibble::tribble(
  ~x, ~y, ~name,
   6, 7, &quot;A&quot;,
   7, 4, &quot;B&quot;,
   2, 2, &quot;C&quot;,
   ) %&gt;%
   ggplot() +
   geom_point(aes(x=x, y=y, color=name), size=10) +
   lims(x=c(0,10), y=c(0,10)) +
   labs(color=&quot;Cell&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-37-1.png" width="576" /></p>
<p>To do that we will first construct a nearest neighbor graph. Therefore, we will run <code>RANN::nn2</code> two times: First we get for each cell in <span class="math inline">\(X\)</span>, the 5 closest cells in <span class="math inline">\(Y\)</span> and then the other way around)</p>
<pre class="r"><code>nn1 &lt;- RANN::nn2(embed_y, embed_x, k=10)
nn2 &lt;- RANN::nn2(embed_x, embed_y, k=10)
nrow(embed_x) == nrow(nn1$nn.idx)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>nrow(embed_y) == nrow(nn2$nn.idx)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Construct the graph. Since we omit the filtering step, we will set <code>k=2</code>, meaning two cells are considered anchors if they are mutual nearest neighbor when we only consider the two nearest neighbors.</p>
<pre class="r"><code>k &lt;- 2
gr &lt;- igraph::graph(c(), n =nrow(nn1$nn.idx) + nrow(nn2$nn.idx))
for(i in 1:k) {
   gr &lt;- igraph::add_edges(
      gr, as.vector(rbind(1:nrow(nn1$nn.idx), nn1$nn.idx[,i] + nrow(nn1$nn.idx)))
      )
}

for(i in 1:k) {
   gr &lt;- igraph::add_edges(
      gr, as.vector(rbind((1:nrow(nn2$nn.idx)) + nrow(nn1$nn.idx),
                         nn2$nn.idx[,i])))
}
gr &lt;- igraph::as.undirected(gr, &quot;mutual&quot; )
anchors &lt;- igraph::as_edgelist(gr)
#anchors[,2] &lt;- anchors[,2] - nrow(nn1$nn.idx)
dim(anchors)</code></pre>
<pre><code>## [1] 6116    2</code></pre>
<pre class="r"><code>head(anchors)</code></pre>
<pre><code>##      [,1] [,2]
## [1,] 1302 7343
## [2,]  359 7346
## [3,] 4530 7347
## [4,] 3829 7348
## [5,] 3621 7349
## [6,] 5622 7349</code></pre>
<details>
<summary>
How does the graph construction work?
</summary>
<ol style="list-style-type: decimal">
<li>We initialize a graph with as many nodes as cells and no edges between them.</li>
</ol>
<pre class="r"><code>g &lt;- igraph::graph(c(), n =nrow(nn1$nn.idx) + nrow(nn2$nn.idx))
g</code></pre>
<pre><code>## IGRAPH 98a1e25 D--- 14662 0 -- 
## + edges from 98a1e25:</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Now we add edges for the <span class="math inline">\(k\)</span> nearest neighbors in <span class="math inline">\(Y\)</span> for each cell in <span class="math inline">\(X\)</span>. We just need to take care of the indices.</li>
</ol>
<pre class="r"><code>k &lt;- 2
for(i in 1:k) {
   g &lt;- igraph::add_edges(
      g, as.vector(rbind(1:nrow(nn1$nn.idx), nn1$nn.idx[,i] + nrow(nn1$nn.idx)))
      )
}
for(i in 1:k) {
   g &lt;- igraph::add_edges(
      g, as.vector(rbind((1:nrow(nn2$nn.idx)) + nrow(nn1$nn.idx),
                         nn2$nn.idx[,i])))
}</code></pre>
<ul>
<li>However, igraph requires us to provide the edges in a weird format. So for <code>i=</code>, we get:</li>
</ul>
<pre class="r"><code>i &lt;- 1
as.vector(rbind(1:nrow(nn1$nn.idx), nn1$nn.idx[,i] + nrow(nn1$nn.idx))) %&gt;%
   head</code></pre>
<pre><code>## [1]    1 7942    2 9273    3 9306</code></pre>
<ul>
<li>This means we will add an edge from the 1. node to the 9960. node, since the first NN for the first cell in <span class="math inline">\(X\)</span> is the 600. cell from <span class="math inline">\(Y\)</span>.</li>
</ul>
<pre class="r"><code>nn1$nn.idx[1:3, 1:5]</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]  600 2618   34 4225  876
## [2,] 1931 7273  309 6304 4620
## [3,] 1964 2325 2982 1946 6396</code></pre>
<ul>
<li>After adjusting the indices by simply adding the number of cells in <span class="math inline">\(X\)</span>, we get:</li>
</ul>
<pre class="r"><code>nn1$nn.idx[1:3, 1:5] + nrow(nn1$nn.idx)</code></pre>
<pre><code>##      [,1]  [,2]  [,3]  [,4]  [,5]
## [1,] 7942  9960  7376 11567  8218
## [2,] 9273 14615  7651 13646 11962
## [3,] 9306  9667 10324  9288 13738</code></pre>
<ul>
<li><p>Which is exactly what we see in the “edge list” above.</p></li>
<li><p>Once the graph is constructed, we transform the graph to be undirected and only keep edges that were present in both directions “mututal.” Whi</p></li>
</ul>
<pre class="r"><code>print(paste0(&quot;The number of edges before: &quot;, igraph::gsize(g)))</code></pre>
<pre><code>## [1] &quot;The number of edges before: 29324&quot;</code></pre>
<pre class="r"><code>g &lt;- igraph::as.undirected(g, mode=&quot;mutual&quot;)
print(paste0(&quot;The number of edges after:  &quot;, igraph::gsize(g)))</code></pre>
<pre><code>## [1] &quot;The number of edges after:  6116&quot;</code></pre>
<hr />
</details>
<p>After finding these integration anchors in the low-dimensional space, they are filtered based on the high-dimensional original space. In particular the 200 (<code>max.features = 200</code>) most informative features for the CCA (i.e. features with the highest loading) are used for filtering. So for each query cell of an anchor cell pair the corresponding reference cell must be among the 200 (<code>k.filter = 200</code>) nearest neighbors in this “high-dimensional space.”</p>
<p>We will omit this filtering step for now.</p>
<p>After filtering the integration anchors are scored based on the overlap on their neighborhood. In particular for both the reference and the query cell the 30 (<code>k.score = 30</code>) nearest neighbors are determined in the same dataset (within-dataset neighbors) and the other-dataset using the low-dimensional embedding. Thus, we have 4 matrices, namely a) the NN of the reference cell from the reference dataset, b) the NN of the reference cell from the query dataset, c) the NN of the query cell from the reference datset, d) the NN of the query cell from the query dataset. Now we determine the overlap between a) and c), as well as b) and d). We combine the overlap measures and call it the score (“how big is the overlap of the neighborhoods”). Furthermore, the effect of outliers is reduced by using the 0.01 and 0.9 quantiles to rescale the anchor scores to a range of 0 to 1.</p>
<pre class="r"><code>k.score &lt;- 30
nnA &lt;- RANN::nn2(embed_x, k=k.score)
nnB &lt;- RANN::nn2(embed_y, embed_x, k=k.score)
nnC &lt;- RANN::nn2(embed_y, k=k.score)
nnD &lt;- RANN::nn2(embed_x, embed_y, k=k.score)

# adjusting the indices
nnB$nn.idx &lt;- nnB$nn.idx + nrow(nnA$nn.idx)
nnC$nn.idx &lt;- nnC$nn.idx + nrow(nnA$nn.idx)</code></pre>
<pre class="r"><code>scores &lt;- vector(mode=&quot;numeric&quot;, length=nrow(anchors))
for (i in 1:nrow(anchors)) {
   anchor_1 &lt;- anchors[i,1]
   anchor_2 &lt;- anchors[i,2]
   l1 &lt;- length(dplyr::intersect(
      nnA$nn.idx[anchor_1,],
      nnD$nn.idx[anchor_2-nrow(nnA$nn.idx),]
   ))
   l2 &lt;- length(dplyr::intersect(
      nnB$nn.idx[anchor_1,],
      nnC$nn.idx[anchor_2-nrow(nnA$nn.idx),]
   ))
   scores[i] &lt;- l1 + l2
}
# &quot;quantile normalization as it is implemented in Seurat!&quot;
scores_rescaled &lt;- 
   (scores - quantile(scores, 0.01)) / 
   (quantile(scores, 0.9) - quantile(scores, 0.01))
scores_rescaled[scores_rescaled &gt; 1] &lt;-  1
scores_rescaled[scores_rescaled &lt; 0] &lt;- 0
hist(scores)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<pre class="r"><code>hist(scores_rescaled)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-47-2.png" width="672" /></p>
</div>
<div id="weight-matrix" class="section level2">
<h2>Weight Matrix</h2>
<p>To correct the expression matrices of <span class="math inline">\(Y\)</span>, we first need to construct the weight matrix <span class="math inline">\(W\)</span>, which described the association between each query cell <span class="math inline">\(c\)</span> and each anchor pair <span class="math inline">\(i\)</span>.</p>
<p>We start by constructing the weighted distance matrix for each query cell <span class="math inline">\(c\)</span> and the <code>k.weight</code> closest anchor pairs (indexed by <span class="math inline">\(i\)</span>) (meaning the query cell from this cell pair). We use the distance to the <code>k.weight</code> nearest anchor query cell as well as the anchor score <span class="math inline">\(S_i\)</span> to weight all the distances. We use the distances based on the pca of the query dataset.</p>
<pre class="r"><code>pca_Y &lt;- rna_list$HC2 %&gt;%
   log_norm() %&gt;%
   .[hvg, ] %&gt;%
   t() %&gt;%
   irlba::prcomp_irlba(., n=30, center = TRUE, scale. = TRUE) %&gt;%
   .[[&quot;x&quot;]]
dim(pca_Y)</code></pre>
<pre><code>## [1] 7320   30</code></pre>
<p><span class="math display">\[
D_{c, i}=\left(1-\frac{\operatorname{dist}\left(c, a_{i}\right)}{\operatorname{dist}\left(c, a_{k . w e i g h t}\right)}\right) S_{a_{i}}
\]</span></p>
<p>We should be able to compute the distances in a vectorized manner</p>
<pre class="r"><code>k.weight = 15
query &lt;- pca_Y
ref &lt;- pca_Y[anchors[,2] - ncol(rna_list$HC1), ]
dim(query)</code></pre>
<pre><code>## [1] 7320   30</code></pre>
<pre class="r"><code>dim(ref)</code></pre>
<pre><code>## [1] 6116   30</code></pre>
<pre class="r"><code>dists &lt;- as.matrix(pdist::pdist(query, ref))
dim(dists)</code></pre>
<pre><code>## [1] 7320 6116</code></pre>
<p>However, we are actually only interested in the <code>k.weight</code> nearest anchor cells for each query cell, so we should set all the values for the other anchors 0.</p>
<p>One easy way would be to get the 30 smallest value in each row, and then set all values larger than that to 0</p>
<pre class="r"><code>for (i in 1:nrow(dists)) {
   if (i %% 1000 == 0) print(i)
   cutoff &lt;- sort(dists[i,],partial=k.weight)[k.weight]
   dists[i, ] &lt;- dists[i, ] / cutoff
   dists[i, dists[i, ] &gt; 1] &lt;- 1
   dists[i, ] &lt;- 1 - dists[i, ]
}</code></pre>
<pre><code>## [1] 1000
## [1] 2000
## [1] 3000
## [1] 4000
## [1] 5000
## [1] 6000
## [1] 7000</code></pre>
<p>Now we multiply with the anchor scores as diagonal matrix. So we basically scale each column corresponding to an anchor by the anchor score.</p>
<pre class="r"><code>weights &lt;- dists %*% diag(scores_rescaled)</code></pre>
<pre class="r"><code>weights[1:6, 1:6]</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,] 0.12    0 0.00 0.00    0    0
## [2,] 0.00    0 0.00 0.00    0    0
## [3,] 0.00    0 0.00 0.00    0    0
## [4,] 0.00    1 0.00 0.00    0    0
## [5,] 0.00    0 0.28 0.00    0    0
## [6,] 0.00    0 0.00 0.16    0    0</code></pre>
<pre class="r"><code>dists[1:6, 1:6]</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]    1    0    0    0    0    0
## [2,]    0    0    0    0    0    0
## [3,]    0    0    0    0    0    0
## [4,]    0    1    0    0    0    0
## [5,]    0    0    1    0    0    0
## [6,]    0    0    0    1    0    0</code></pre>
<pre class="r"><code>scores_rescaled[1:6]</code></pre>
<pre><code>## [1] 0.12 1.00 0.28 0.16 0.60 0.32</code></pre>
<p>Now we apply a Gaussian kernel. So the weights decay according to a “Gaussian Curve” with increasing distance.</p>
<p><span class="math display">\[
\tilde{D}_{c, i}=1-\mathrm{e}^{\frac{-D_{c, i}}{(2 / s d)^{2}}}
\]</span></p>
<pre class="r"><code>bandwidth &lt;- 1
weights_corrected &lt;- 1 - exp(
   - weights/
      (2/bandwidth)^2
   )
weights_corrected[1:6, 1:6]</code></pre>
<pre><code>##            [,1]      [,2]       [,3]       [,4] [,5] [,6]
## [1,] 0.02955447 0.0000000 0.00000000 0.00000000    0    0
## [2,] 0.00000000 0.0000000 0.00000000 0.00000000    0    0
## [3,] 0.00000000 0.0000000 0.00000000 0.00000000    0    0
## [4,] 0.00000000 0.2211992 0.00000000 0.00000000    0    0
## [5,] 0.00000000 0.0000000 0.06760618 0.00000000    0    0
## [6,] 0.00000000 0.0000000 0.00000000 0.03921056    0    0</code></pre>
<p>where sd is the Gaussian kernel bandwidth, set to 1 by default.</p>
<p>Finally, we normalize across all k.weight anchors, meaning we divide each row by the row sum.</p>
<p><span class="math display">\[
W_{c, i}=\frac{\tilde{D}_{c, i}}{\sum_{1}^{j=k . \text { weight }} \tilde{D}_{c, j}}
\]</span></p>
<pre class="r"><code>W &lt;- weights_corrected / Matrix::rowSums(weights_corrected)
W[1:6, 1:6]</code></pre>
<pre><code>##           [,1]      [,2]      [,3]      [,4] [,5] [,6]
## [1,] 0.3932271 0.0000000 0.0000000 0.0000000    0    0
## [2,] 0.0000000 0.0000000 0.0000000 0.0000000    0    0
## [3,] 0.0000000 0.0000000 0.0000000 0.0000000    0    0
## [4,] 0.0000000 0.3708784 0.0000000 0.0000000    0    0
## [5,] 0.0000000 0.0000000 0.3609311 0.0000000    0    0
## [6,] 0.0000000 0.0000000 0.0000000 0.2098016    0    0</code></pre>
<pre class="r"><code>dim(W)</code></pre>
<pre><code>## [1] 7320 6116</code></pre>
</div>
<div id="correct-expression" class="section level2">
<h2>Correct Expression</h2>
<p>We first need to compute matrix B, where each column corresponds to the difference between the expression vectors of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> for the cells of anchor pair <span class="math inline">\(i\)</span>.</p>
<p>I am just not sure whether we should use the counts or the log normalized counts here? I guess normalized makes more sense as we need to account for differences in the library size.</p>
<pre class="r"><code>X &lt;- rna_list$HC1 %&gt;% log_norm()
Y &lt;- rna_list$HC2 %&gt;% log_norm()
B &lt;- Y[, anchors[,2] - ncol(X)] - X[, anchors[,1]]
dim(B)</code></pre>
<pre><code>## [1] 13523  6116</code></pre>
<p>Now we can compute the transformation matrix <span class="math inline">\(C = BW^T\)</span>:</p>
<pre class="r"><code>C &lt;- B %*% t(W)
dim(C)</code></pre>
<pre><code>## [1] 13523  7320</code></pre>
<p>And lastly we subtract the transformation matrix <span class="math inline">\(C\)</span> from <span class="math inline">\(Y\)</span> to get the integrated expression matrix <span class="math inline">\(\hat{Y} = Y - C\)</span></p>
<pre class="r"><code>Y_hat &lt;- Y - C</code></pre>
<p>Now let’s do again a pca on <span class="math inline">\([X, \hat{Y}]\)</span> and check whether we see a batch effect.</p>
<pre class="r"><code>pca_test &lt;- irlba::prcomp_irlba(
   t(cbind(X, Y_hat)[hvg, ]), n = 30
)
ggplot() +
   geom_point(aes(x=pca_test$x[,1], y=pca_test$x[,2],
                  color = str_extract(colnames(do.call(cbind, rna_list[c(&quot;HC1&quot;, &quot;HC2&quot;)])), &quot;S[0-9]|HC[0-9]&quot;)),
              size=0.1, alpha=0.5) +
   labs(color=&quot;Sample&quot;)</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>And what about the UMAP?</p>
<pre class="r"><code>umap_test &lt;- uwot::umap(pca_test$x)</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre><code>## Found more than one class &quot;dist&quot; in cache; using the first, from namespace &#39;BiocGenerics&#39;</code></pre>
<pre><code>## Also defined by &#39;spam&#39;</code></pre>
<pre class="r"><code>ggplot() +
   geom_point(aes(x=umap_test[,1], y=umap_test[,2],
                  color = str_extract(rownames(rbind(embed_x, embed_y)),
                                      &quot;HC[0-9]|M[0-9]|S[0-9]&quot;)),
              size=0.2, alpha=0.2) +
   labs(color=&quot;Sample&quot;) +
   guides(color = guide_legend(override.aes = list(size = 2,
                                                   alpha=1)))</code></pre>
<p><img src="integration_cca_2_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
</div>
</div>
<div id="integration-of-scrna-and-scatac-data" class="section level1">
<h1>Integration of scRNA and scATAC data</h1>
<p>TODO</p>
<div id="transfer-data" class="section level2">
<h2>Transfer Data</h2>
<div id="discrete-data" class="section level3">
<h3>Discrete Data</h3>
<p>For cell metadata transfer, we create a binary classification matrix <span class="math inline">\(L\)</span> containing the classification information for each anchor cell in the reference dataset. Specifically, each row in <span class="math inline">\(L\)</span> corresponds to a possible class and each column corresponds to a reference anchor.</p>
<p>If the reference cell in the anchor belongs to the corresponding class, that entry in the matrix is filled with a <span class="math inline">\(1\)</span>, otherwise the entry is assigned a <span class="math inline">\(0\)</span>.</p>
<p>We then compute label predictions, <span class="math inline">\(P_{l}\)</span>, by multiplying the anchor classification matrix <span class="math inline">\(L\)</span> with the transpose of the weights matrix <span class="math inline">\(W\)</span> :</p>
<p><span class="math display">\[
P_{l}=L W^{T}
\]</span></p>
<p>This returns a prediction score for each class for every cell in the query dataset that ranges from 0 to 1 , and sums to <span class="math inline">\(1\)</span>.</p>
</div>
<div id="continuous-data" class="section level3">
<h3>Continuous Data</h3>
<p>Our procedure for transferring continuous data is closely related to discrete label transfer.</p>
<p>We compute new feature expression predictions, <span class="math inline">\(P_{f}\)</span>, by multiplying a matrix of anchor features to be transferred, <span class="math inline">\(F\)</span>, with the transpose of the weights matrix <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[
P_{f}=F W^{T}
\]</span></p>
<p>In words: For a given query cell <span class="math inline">\(c\)</span> we get a the sum of the classes of their closest anchor cells weighted by the distance and the score of that anchor pair.</p>
<p><img src="img/discrete_transfer.png" width="100%" style="display: block; margin: auto;" /></p>
<p>This returns a predicted expression matrix for each feature (row) in <span class="math inline">\(F\)</span> for each cell in the query dataset.</p>
</div>
</div>
</div>
<div id="questions" class="section level1">
<h1>Questions</h1>
<ol style="list-style-type: decimal">
<li>What is the effect of different proportions of cell types?</li>
</ol>
</div>
<div id="referencess" class="section level1 unnumbered">
<h1 class="unnumbered">Referencess</h1>
<div id="refs" class="references csl-bib-body">
<div id="ref-10.1093/biostatistics/kxp008" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">D. M. Witten, R. Tibshirani, T. Hastie, <span class="nocase">A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</span>. <em>Biostatistics</em>. <strong>10</strong>, 515–534 (2009).</div>
</div>
<div id="ref-10.1038/nbt.4096" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">A. Butler, P. Hoffman, P. Smibert, E. Papalexi, R. Satija, <span class="nocase">Integrating single-cell transcriptomic data across different conditions, technologies, and species</span>. <em>Nature Biotechnology</em>. <strong>36</strong>, 411–420 (2018).</div>
</div>
<div id="ref-10.1016/j.cell.2019.05.031" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">T. Stuart, A. Butler, P. Hoffman, C. Hafemeister, E. Papalexi, W. M. Mauck, Y. Hao, M. Stoeckius, P. Smibert, R. Satija, <span class="nocase">Comprehensive Integration of Single-Cell Data</span>. <em>Cell</em>. <strong>177</strong>, 1888–1902.e21 (2019).</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
